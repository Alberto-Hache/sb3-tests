{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Baselines3 Tutorial - Getting Started\n",
    "- Create a basic RL model.\n",
    "- Train it in a custom env.\n",
    "- Evaluate it.\n",
    "\n",
    "Also:\n",
    "- Record a video of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of model and env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously, install ffmpeg freeglut3-dev xvfb  (for visualization).\n",
    "\n",
    "# Imports\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Import the RL model.\n",
    "from stable_baselines3 import PPO # RL algorithm.\n",
    "from stable_baselines3.ppo.policies import MlpPolicy # MLP as policy for a feature vector (no image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gym env:\n",
    "# The action space is deduced from the env. action space.\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Instantiate the agent:\n",
    "# PPO (actor-critic, using a value function to improve the policy).\n",
    "# MlpPolicy because the observation of the CartPole task is a feature vector, not images.\n",
    "model = PPO(MlpPolicy, env, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate the agent.\n",
    "def evaluate(model, num_episodes=100):\n",
    "    env = model.get_env() # Use the env. of the model.\n",
    "    all_episode_rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        episode_rewards = []\n",
    "        done = False\n",
    "        obs = env.reset() # Initialize env; first observation.\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs) # states are only useful with LSTM policies.\n",
    "            obs, reward, done, info = env.step(action) # returns arrays (bc vecotirzed env.)\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "        all_episode_rewards.append(sum(episode_rewards))\n",
    "    \n",
    "    mean_episode_reward = np.mean(all_episode_rewards)\n",
    "    print(f'Mean reward: {mean_episode_reward}, Num episodes: {num_episodes}')\n",
    "\n",
    "    return mean_episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 22.219999313354492, Num episodes: 100\n"
     ]
    }
   ],
   "source": [
    "# Random agent, before training\n",
    "mean_reward_before_train = evaluate(model, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 40.06 +/- 16.02\n"
     ]
    }
   ],
   "source": [
    "# Using Stable Baselines 3's helper.\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alberto/Code/RLtest1/.venv/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 396.80 +/- 114.51\n"
     ]
    }
   ],
   "source": [
    "# Train the agent adn evaluate it.\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\n",
      "_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\n",
      "_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\n"
     ]
    }
   ],
   "source": [
    "# Set up fake display; otherwise rendering will fail.\n",
    "import os\n",
    "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
    "os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "def show_videos(video_path='', prefix=''):\n",
    "  \"\"\"\n",
    "  Taken from https://github.com/eleurent/highway-env\n",
    "\n",
    "  :param video_path: (str) Path to the folder containing videos\n",
    "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
    "  \"\"\"\n",
    "  html = []\n",
    "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
    "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "      html.append('''<video alt=\"{}\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "\n",
    "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
    "  \"\"\"\n",
    "  :param env_id: (str)\n",
    "  :param model: (RL model)\n",
    "  :param video_length: (int)\n",
    "  :param prefix: (str)\n",
    "  :param video_folder: (str)\n",
    "  \"\"\"\n",
    "  eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "  # Start the video at step=0 and record 500 steps\n",
    "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
    "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
    "                              name_prefix=prefix)\n",
    "\n",
    "  obs = eval_env.reset()\n",
    "  for _ in range(video_length):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _, _ = eval_env.step(action)\n",
    "\n",
    "  # Close the video recorder\n",
    "  eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/Alberto/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/Alberto/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/Alberto/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/Alberto/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/Alberto/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "# Record and save the video.\n",
    "record_video('CartPole-v1', model, video_length=500, prefix='ppo2-cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a25fab064cd93c11456bb88c41d634ca058856b88a784e3a94d171d100adf666"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
